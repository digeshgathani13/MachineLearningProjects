{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = 'Hi how are you'\n",
    "document2 = 'Today is very very very pleasent day and we can have some fun fun fun'\n",
    "document3 = 'This was an amazine experiance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofdocuments = [document1,document2,document3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vectorizer.fit(listofdocuments)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 19)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t3\n",
      "  (1, 8)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 16)\t3\n",
      "  (1, 18)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 17)\t1\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vectorizer.transform(listofdocuments)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_.get('very'))\n",
    "print(vectorizer.vocabulary_.get('fun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bag_of_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
